add_annotations( text="Policy Id", xref="paper", yref="paper",
x=1.02, xanchor="left",
y=0.65, yanchor="bottom",    # Same y as legend below
legendtitle=TRUE, showarrow=FALSE )  %>%
layout(margin = list(l=25, r=50, b=10, t=50, pad=1), legend=list(yanchor="top", tracegroupgap=0.1, font=list(size = 3), orientation = "h", x = 1.02, y = 0.65), xaxis=list(tickangle=270, title = "\n Location (Local Authority)", tickfont = list(size = '15')))
# fig$height  = "100%"
# fig$width = "100%"
fig %>% config(displayModeBar = F)
runApp()
p <- ggplot(cvdData, aes(`Local Authority`)) + theme_bw() + geom_line(size = 0.5, na.rm=TRUE, aes(y = LLD_SD_ActualCases_wk46, linetype = "Number of Actual Cases for wk 46: Local lockdown with social distancing", group = 1, color=colorSet2[1])) + geom_line(size = 0.5, na.rm=TRUE, aes(y = LLD_SD_ForecastCases_wk51_Retail50Pct, linetype = "Cases Forecast for wk 51: Local lockdown with social distancing and 50% retail closing", group = 1, color=colorSet2[2])) + geom_line(size = 0.5, na.rm=TRUE, aes(y = LLD_SD_ForecastCases_wk51_FoodAccom50Pct, linetype = "Cases Forecast for wk 51: Local lockdown with social distancing and 50% food & accom closing", group = 1, color=colorSet2[3])) + geom_line(size = 0.5, na.rm=TRUE, aes(y = LLD_SD_ForecastCases_wk51_pub50Pct, linetype = "Cases Forecast for wk 51: Local lockdown with social distancing and 50% pubs closing", group = 1, color=colorSet2[4])) + geom_line(size = 0.5, na.rm=TRUE, aes(y = LLD_SD_ForecastCases_wk51_quarantine100Pct, linetype = "Cases Forecast for wk 51: Local lockdown with social distancing and 100% travel quarantine", group = 1, color=colorSet2[5])) + geom_line(size = 0.5, na.rm=TRUE, aes(y = LLD_SD_ForecastCases_wk51_SchoolOpen50Pct, linetype = "Cases Forecast for wk 51: Local lockdown with social distancing and 50% schools closing", group = 1, color=colorSet2[6])) + geom_line(size = 0.5, na.rm=TRUE, aes(y = LLD_SD_ForecastCases_wk51_IntTravel50Pct, linetype = "Cases Forecast for wk 51: Local lockdown with social distancing and 50% international airports closing", group = 1, color=colorSet2[7])) + geom_line(size = 0.5, na.rm=TRUE, aes(y = FLD_ForecastCases_wk51, linetype = "Cases Forecast for wk 51: Full lockdown", group = 1, color=colorSet2[8])) + labs(color=NULL) + theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1, margin=margin(5,0,7,0),face="bold")) + xlab("Week") + ylab("Count") + ggtitle("Effect: cases by policy") + theme(legend.margin=margin(10, 0, 50, 0), plot.title = element_text(hjust = 0.5)) + guides(color = guide_legend(override.aes = list(size = 1.5)))
# ggplotly =====================================================
fig <- ggplotly(p, autosize = F, width = 650, height = 500)
fig <- plotly_build(fig)
fig$x$layout$annotations[[1]]$text <- ''
for (i in seq_along(fig$x$data) ) {
fig$x$data[[i]]$text <- sub("as.factor.*", "", fig$x$data[[i]]$text)
}
fig <- fig %>%
add_annotations( text="Policy Id", xref="paper", yref="paper",
x=1.02, xanchor="left",
y=0.65, yanchor="bottom",    # Same y as legend below
legendtitle=TRUE, showarrow=FALSE )  %>%
layout(margin = list(l=25, r=50, b=10, t=50, pad=1), legend=list(yanchor="top", tracegroupgap=0.1, font=list(size = 3), orientation = "h", x = 1.02, y = 0.5), xaxis=list(tickangle=270, title = "\n Location (Local Authority)", tickfont = list(size = '15')))
# fig$height  = "100%"
# fig$width = "100%"
fig %>% config(displayModeBar = F)
p <- ggplot(cvdData, aes(`Local Authority`)) + theme_bw() + geom_line(size = 0.5, na.rm=TRUE, aes(y = LLD_SD_ActualCases_wk46, linetype = "Number of Actual Cases for wk 46: Local lockdown with social distancing", group = 1, color=colorSet2[1])) + geom_line(size = 0.5, na.rm=TRUE, aes(y = LLD_SD_ForecastCases_wk51_Retail50Pct, linetype = "Cases Forecast for wk 51: Local lockdown with social distancing and 50% retail closing", group = 1, color=colorSet2[2])) + geom_line(size = 0.5, na.rm=TRUE, aes(y = LLD_SD_ForecastCases_wk51_FoodAccom50Pct, linetype = "Cases Forecast for wk 51: Local lockdown with social distancing and 50% food & accom closing", group = 1, color=colorSet2[3])) + geom_line(size = 0.5, na.rm=TRUE, aes(y = LLD_SD_ForecastCases_wk51_pub50Pct, linetype = "Cases Forecast for wk 51: Local lockdown with social distancing and 50% pubs closing", group = 1, color=colorSet2[4])) + geom_line(size = 0.5, na.rm=TRUE, aes(y = LLD_SD_ForecastCases_wk51_quarantine100Pct, linetype = "Cases Forecast for wk 51: Local lockdown with social distancing and 100% travel quarantine", group = 1, color=colorSet2[5])) + geom_line(size = 0.5, na.rm=TRUE, aes(y = LLD_SD_ForecastCases_wk51_SchoolOpen50Pct, linetype = "Cases Forecast for wk 51: Local lockdown with social distancing and 50% schools closing", group = 1, color=colorSet2[6])) + geom_line(size = 0.5, na.rm=TRUE, aes(y = LLD_SD_ForecastCases_wk51_IntTravel50Pct, linetype = "Cases Forecast for wk 51: Local lockdown with social distancing and 50% international airports closing", group = 1, color=colorSet2[7])) + geom_line(size = 0.5, na.rm=TRUE, aes(y = FLD_ForecastCases_wk51, linetype = "Cases Forecast for wk 51: Full lockdown", group = 1, color=colorSet2[8])) + labs(color=NULL) + theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1, margin=margin(5,0,7,0),face="bold")) + xlab("Week") + ylab("Count") + ggtitle("Effect: cases by policy") + theme(legend.margin=margin(10, 0, 50, 0), plot.title = element_text(hjust = 0.5)) + guides(color = guide_legend(override.aes = list(size = 1.5)))
# ggplotly =====================================================
fig <- ggplotly(p, autosize = F, width = 650, height = 500)
fig <- plotly_build(fig)
fig$x$layout$annotations[[1]]$text <- ''
for (i in seq_along(fig$x$data) ) {
fig$x$data[[i]]$text <- sub("as.factor.*", "", fig$x$data[[i]]$text)
}
fig <- fig %>%
add_annotations( text="Policy Id", xref="paper", yref="paper",
x=1.02, xanchor="left",
y=0.75, yanchor="bottom",    # Same y as legend below
legendtitle=TRUE, showarrow=FALSE )  %>%
layout(margin = list(l=25, r=50, b=10, t=50, pad=1), legend=list(yanchor="top", tracegroupgap=0.1, font=list(size = 3), orientation = "h", x = 1.02, y = 0.75), xaxis=list(tickangle=270, title = "\n Location (Local Authority)", tickfont = list(size = '15')))
# fig$height  = "100%"
# fig$width = "100%"
fig %>% config(displayModeBar = F)
p <- ggplot(cvdData, aes(`Local Authority`)) + theme_bw() + geom_line(size = 0.5, na.rm=TRUE, aes(y = LLD_SD_ActualCases_wk46, linetype = "Number of Actual Cases for wk 46: Local lockdown with social distancing", group = 1, color=colorSet2[1])) + geom_line(size = 0.5, na.rm=TRUE, aes(y = LLD_SD_ForecastCases_wk51_Retail50Pct, linetype = "Cases Forecast for wk 51: Local lockdown with social distancing and 50% retail closing", group = 1, color=colorSet2[2])) + geom_line(size = 0.5, na.rm=TRUE, aes(y = LLD_SD_ForecastCases_wk51_FoodAccom50Pct, linetype = "Cases Forecast for wk 51: Local lockdown with social distancing and 50% food & accom closing", group = 1, color=colorSet2[3])) + geom_line(size = 0.5, na.rm=TRUE, aes(y = LLD_SD_ForecastCases_wk51_pub50Pct, linetype = "Cases Forecast for wk 51: Local lockdown with social distancing and 50% pubs closing", group = 1, color=colorSet2[4])) + geom_line(size = 0.5, na.rm=TRUE, aes(y = LLD_SD_ForecastCases_wk51_quarantine100Pct, linetype = "Cases Forecast for wk 51: Local lockdown with social distancing and 100% travel quarantine", group = 1, color=colorSet2[5])) + geom_line(size = 0.5, na.rm=TRUE, aes(y = LLD_SD_ForecastCases_wk51_SchoolOpen50Pct, linetype = "Cases Forecast for wk 51: Local lockdown with social distancing and 50% schools closing", group = 1, color=colorSet2[6])) + geom_line(size = 0.5, na.rm=TRUE, aes(y = LLD_SD_ForecastCases_wk51_IntTravel50Pct, linetype = "Cases Forecast for wk 51: Local lockdown with social distancing and 50% international airports closing", group = 1, color=colorSet2[7])) + geom_line(size = 0.5, na.rm=TRUE, aes(y = FLD_ForecastCases_wk51, linetype = "Cases Forecast for wk 51: Full lockdown", group = 1, color=colorSet2[8])) + labs(color=NULL) + theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1, margin=margin(5,0,7,0),face="bold")) + xlab("Week") + ylab("Count") + ggtitle("Effect: cases by policy") + theme(legend.margin=margin(10, 0, 50, 0), plot.title = element_text(hjust = 0.5)) + guides(color = guide_legend(override.aes = list(size = 1.5)))
# ggplotly =====================================================
fig <- ggplotly(p, autosize = F, width = 650, height = 500)
fig <- plotly_build(fig)
fig$x$layout$annotations[[1]]$text <- ''
for (i in seq_along(fig$x$data) ) {
fig$x$data[[i]]$text <- sub("as.factor.*", "", fig$x$data[[i]]$text)
}
fig <- fig %>%
add_annotations( text="Policy Id", xref="paper", yref="paper",
x=1.02, xanchor="left",
y=0.85, yanchor="bottom",    # Same y as legend below
legendtitle=TRUE, showarrow=FALSE )  %>%
layout(margin = list(l=25, r=50, b=10, t=50, pad=1), legend=list(yanchor="top", tracegroupgap=0.1, font=list(size = 3), orientation = "h", x = 1.02, y = 0.85), xaxis=list(tickangle=270, title = "\n Location (Local Authority)", tickfont = list(size = '15')))
# fig$height  = "100%"
# fig$width = "100%"
fig %>% config(displayModeBar = F)
runApp()
p <- ggplot(cvdData, aes(`Local Authority`)) + theme_bw() + geom_line(size = 0.5, na.rm=TRUE, aes(y = LLD_SD_ActualCases_wk46, linetype = "Number of Actual Cases for wk 46: Local lockdown with social distancing", group = 1, color=colorSet2[1])) + geom_line(size = 0.5, na.rm=TRUE, aes(y = LLD_SD_ForecastCases_wk51_Retail50Pct, linetype = "Cases Forecast for wk 51: Local lockdown with social distancing and 50% retail closing", group = 1, color=colorSet2[2])) + geom_line(size = 0.5, na.rm=TRUE, aes(y = LLD_SD_ForecastCases_wk51_FoodAccom50Pct, linetype = "Cases Forecast for wk 51: Local lockdown with social distancing and 50% food & accom closing", group = 1, color=colorSet2[3])) + geom_line(size = 0.5, na.rm=TRUE, aes(y = LLD_SD_ForecastCases_wk51_pub50Pct, linetype = "Cases Forecast for wk 51: Local lockdown with social distancing and 50% pubs closing", group = 1, color=colorSet2[4])) + geom_line(size = 0.5, na.rm=TRUE, aes(y = LLD_SD_ForecastCases_wk51_quarantine100Pct, linetype = "Cases Forecast for wk 51: Local lockdown with social distancing and 100% travel quarantine", group = 1, color=colorSet2[5])) + geom_line(size = 0.5, na.rm=TRUE, aes(y = LLD_SD_ForecastCases_wk51_SchoolOpen50Pct, linetype = "Cases Forecast for wk 51: Local lockdown with social distancing and 50% schools closing", group = 1, color=colorSet2[6])) + geom_line(size = 0.5, na.rm=TRUE, aes(y = LLD_SD_ForecastCases_wk51_IntTravel50Pct, linetype = "Cases Forecast for wk 51: Local lockdown with social distancing and 50% international airports closing", group = 1, color=colorSet2[7])) + geom_line(size = 0.5, na.rm=TRUE, aes(y = FLD_ForecastCases_wk51, linetype = "Cases Forecast for wk 51: Full lockdown", group = 1, color=colorSet2[8])) + labs(color=NULL) + theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1, margin=margin(5,0,7,0),face="bold")) + xlab("Week") + ylab("Count") + ggtitle("Effect: cases by policy") + theme(legend.margin=margin(10, 0, 50, 0), plot.title = element_text(hjust = 0.5)) + guides(color = guide_legend(override.aes = list(size = 1.5)))
# ggplotly =====================================================
fig <- ggplotly(p, autosize = F, width = 650, height = 500)
fig <- plotly_build(fig)
fig$x$layout$annotations[[1]]$text <- ''
for (i in seq_along(fig$x$data) ) {
fig$x$data[[i]]$text <- sub("as.factor.*", "", fig$x$data[[i]]$text)
}
fig <- fig %>%
add_annotations( text="Policy Id", xref="paper", yref="paper",
x=1.02, xanchor="left",
y=0.85, yanchor="bottom",    # Same y as legend below
legendtitle=TRUE, showarrow=FALSE )  %>%
layout(legend=list(yanchor="top", tracegroupgap=0.1, font=list(size = 3), orientation = "h", x = 1.02, y = 0.85), xaxis=list(tickangle=270, title = "\n Location (Local Authority)", tickfont = list(size = '15')))
# fig$height  = "100%"
# fig$width = "100%"
fig %>% config(displayModeBar = F)
runApp()
runApp()
jointWeekNCases_Mltd_timeSpSortedScaled
library(shiny)
library(ggplot2)
# User interface ----
library(shinythemes)
library(shinyWidgets)
# Geomapping -----
# library(rgdal)
# library(rgeos)
# library(tidyverse)
# library(stringr)
# library(spatialEco)
# library(plyr)
# library(dplyr)
# Geomapping -----
library(data.table)
library(sf)
#library(tmap)
library(sp)
library(mapview)
library(raster)
#leafgl
library(leaflet)
#library(leafgl)
library(colourvalues)
#date conversion
library(xts)
#funnel plot
library(funnelR)
#adding columns
library(tibble)
#for melting dataframe
library(reshape2)
#for interactive plot
library(plotly)
#for logo dashboardheader
library(shinydashboard)
#mixedsort
library(gtools)
#for finding element in string
library(stringi)
library(keras)
#use_condaenv("plaidml")  # only switch on in Mac os environment
#for hidden sidebar widgets
library(shinyjs)
#for copying objects without reference
library(rlang)
#parse numbers
library(readr)
#add help icon
library(shinyhelper)
#remove any unnecessary variables
rm(list=ls())
gc()
# Load data ----
#cvdData <- fread('data/MSOAs_latest.csv', data.table=FALSE)
cvdData <- fread('data/MSOAs_latest.csv', data.table=FALSE)
#deprivIndx <- fread('data/File_2_-_IoD2019_Domains_of_Deprivation.csv', select=c('LocAuthDistrict_2019', 'IMD_Rank', 'IMD_Decile', 'Income_Rank', 'Income_Decile', 'Employment_Rank', 'Employment_Decile', 'Education_Skills_Training_Rank', 'Education_Skills _Training Decile', 'Health_Deprivation_Disability_Rank', 'Health_Deprivation_Disability_Decile', 'Crime_Rank', 'Crime_Decile', 'Barriers_to_Housing_and_Services_Rank', 'Barriers_to_Housing_and_Services_Decile', 'Living_Environment_Rank', 'Living_Environment_Decile'), data.table=FALSE)
#pubSize <- fread('data/publichousesandbarsbylocalauthority20012018.csv', select=c('Area code', 'count_2018'), data.table=FALSE)
deprivIndx <- fread('data/File_2_-_IoD2019_Domains_of_Deprivation.csv',  select=c('LocAuthDistrict_2019', 'IMD_Rank', 'IMD_Decile', 'Income_Rank', 'Income_Decile', 'Employment_Rank', 'Employment_Decile', 'Education_Skills_Training_Rank', 'Education_Skills _Training Decile', 'Health_Deprivation_Disability_Rank', 'Health_Deprivation_Disability_Decile', 'Crime_Rank', 'Crime_Decile', 'Barriers_to_Housing_and_Services_Rank', 'Barriers_to_Housing_and_Services_Decile', 'Living_Environment_Rank', 'Living_Environment_Decile'), data.table=FALSE)
pubSize <- fread('data/publichousesandbarsbylocalauthority20012018.csv',  select=c('Area code', 'count_2018'), data.table=FALSE)
#industrySize <- fread('data/ukbusinessworkbook2020.csv', select=c('Local_AuthCode_2020', 'Retail', 'Transport_Storage_inc_postal', 'Accommodation_food_services', 'Education', 'Health', 'Arts_entertainment_recreation_other_services'), data.table=FALSE)
industrySize <- fread('data/ukbusinessworkbook2020.csv',  select=c('Local_AuthCode_2020', 'Retail', 'Transport_Storage_inc_postal', 'Accommodation_food_services', 'Education', 'Health', 'Arts_entertainment_recreation_other_services'), data.table=FALSE)
deprivIndx[] <- lapply(deprivIndx, gsub, pattern=',', replacement='')
deprivIndx[,2:ncol(deprivIndx)] <- lapply(deprivIndx[,2:ncol(deprivIndx)], as.numeric)
# aggregate to obtain mean deprivation indices by unique local authority districts
meanDprvIndByLA <- aggregate(formula=.~LocAuthDistrict_2019, data=deprivIndx, FUN=mean)
# Local Authority data -----------------------------------------------------
# lsoaLAuthLookup <- fread("C:\\Installation WorkPCToLaptop\\Dashboard\\cardioDshBCvdDL\\data\\2019PopulationEstimateEngWal\\boundaryLines\\LocalAuthorityEngW_2011\\LSOA_to_Local_Authority_2017_Lookup.csv", select=c('LSOA11CD', 'LAD17NM'), data.table=FALSE)
# Local Authority data -----------------------------------------------------
# get location and weekly cases columns
# casesCols <- cvdData[,c(5, 6, 9:ncol(cvdData))]
# #do this for only liverpool initially
# #casesCols <- casesCols[casesCols$lad19_nm == "Liverpool", ]
# names(casesCols)[length(names(casesCols))]<-"wk_41"
# #remove NA columns
# casesCols <- casesCols[, colSums(is.na(casesCols)) != nrow(casesCols)]
# # aggregate to obtain count by unique local authority districts
# casesByLA <- aggregate(formula=.~lad19_cd+lad19_nm, data=casesCols, FUN=sum)
# remove LA names not in casesByLA
# deprivIndx <- deprivIndx[deprivIndx$LocAuthDistrict_2019 %in% as.character(casesByLA$lad19_cd),]
# # remove duplicate LA codes
# deprivIndxUniq <- deprivIndx[!duplicated(deprivIndx$LocAuthDistrict_2019),]
# # merge casesByLA LA code with deprivIndxUniq LA code
# casesByLA_DprvInd <- merge(casesByLA, deprivIndxUniq, by.x="lad19_cd",by.y="LocAuthDistrict_2019")
# merge pub size data -------------------------------------------------------------------
pubSize$count_2018 <- gsub(',', '', pubSize$count_2018)
pubSize$count_2018 <- as.numeric(pubSize$count_2018)
# aggregate to obtain count by unique local authority districts
pubCountByLA <- aggregate(formula=.~`Area code`, data=pubSize, FUN=sum)
# remove LA names not in deprivIndx
pubCountByLA <- pubCountByLA[pubCountByLA$`Area code` %in% as.character(meanDprvIndByLA$LocAuthDistrict_2019),]
# remove duplicate LA codes
pubCountByLAUniq <- pubCountByLA[!duplicated(pubCountByLA$`Area code`),]
# merge deprivIndx LA code with pubCountByLAUniq: 312 unique LA codes out of 318 remain after joining deprivation and pub
pubCntByLA_DprvInd_Pub <- merge(pubCountByLAUniq, meanDprvIndByLA, by.x="Area code", by.y="LocAuthDistrict_2019")
names(pubCntByLA_DprvInd_Pub)[names(pubCntByLA_DprvInd_Pub) == "count_2018"] <- "pub_count_2018"
# merge pub size data -------------------------------------------------------------------
# merge industry size data -------------------------------------------------------------------
industrySize[] <- lapply(industrySize, gsub, pattern=',', replacement='')
# remove LA names not in pubCntByLA_DprvInd_Pub
industrySize <- industrySize[industrySize$Local_AuthCode_2020 %in% as.character(pubCntByLA_DprvInd_Pub$`Area code`),]
# remove duplicate LA codes
industrySizeUniq <- industrySize[!duplicated(industrySize$Local_AuthCode_2020),]
# merge pubCntByLA_DprvInd_Pub LA code with industrySizeUniq LA code
pubCntByLA_DprvInd_Pub_Indstr <- merge(pubCntByLA_DprvInd_Pub, industrySizeUniq, by.x="Area code",by.y="Local_AuthCode_2020")
# merge industry size data -------------------------------------------------------------------
# read population estimates 2019 -------------------------------------------------
femalesPpltn <- fread('data/femalePpltn2019ladcodes.csv', select=c('Code', 'All_females'), data.table=FALSE)
malesPpltn <- fread('data/malePpltn2019ladcodes.csv', select=c('Code', 'All_males'), data.table=FALSE)
inFlowPpltn <- fread('data/migrationFlow2019ladcodes.csv', data.table=FALSE)
agePpltn <- fread('data/age_2019ladcodes.csv', data.table=FALSE)
ppltnEst10yrs <- Reduce((function() {counter = 1
function(x, y) {
counter <<- counter + 1
d = merge(x, y, by = 'Code')
}})(), list(femalesPpltn, malesPpltn, inFlowPpltn, agePpltn))
#merge needs to be done
ppltnEst10yrs[] <- lapply(ppltnEst10yrs, gsub, pattern=',', replacement='')
# remove LA names not in pubCntByLA_DprvInd_Pub_Indstr
ppltnEst10yrs <- ppltnEst10yrs[ppltnEst10yrs$Code %in% as.character(pubCntByLA_DprvInd_Pub_Indstr$`Area code`),]
# remove duplicate LA codes
ppltnEst10yrsUniq <- ppltnEst10yrs[!duplicated(ppltnEst10yrs$Code),]
# merge pubCntByLA_DprvInd_Pub_Indstr LA code with ppltnEst10yrsUniq LA code
pubCntByLA_DprvInd_PubIndstr_ppltn <- merge(pubCntByLA_DprvInd_Pub_Indstr, ppltnEst10yrsUniq, by.x="Area code",by.y="Code")
pubCntByLA_DprvInd_PubIndstr_ppltn$Name <- NULL
# read population estimates 2019 -------------------------------------------------
# if by PHE Region --------------------------------------------------------------------------------------------
# Public health england region ----------------------------------------------------
lAuthPHE_Lkup <- fread('data/Local_Authority_to_PHE_Region_Dec_2019_Lookup_Eng.csv', select=c('LAD19CD', 'LAD19NM', 'PHEC19CD', 'PHEC19NM'), data.table=FALSE)
phe_CentresBndryLn <- st_read("data/Public_Health_England_Centres__December_2016__Boundaries.shp")
phe_CentresBndryLn$phec16nm <- NULL
phe_CentresBndryLn$bng_e <- NULL
phe_CentresBndryLn$bng_n <- NULL
phe_CentresBndryLn$st_areasha <- NULL
phe_CentresBndryLn$st_lengths <- NULL
phe_CentresBndryLn$objectid <- NULL
# remove LA codes not in pubCntByLA_DprvInd_PubIndstr_ppltn
lAuthPHE_Lkup <- lAuthPHE_Lkup[lAuthPHE_Lkup$LAD19CD %in% as.character(pubCntByLA_DprvInd_PubIndstr_ppltn$`Area code`),]
# remove duplicate LA codes
lAuthPHE_LkupUniq <- lAuthPHE_Lkup[!duplicated(lAuthPHE_Lkup$LAD19CD),]
# merge pubCntByLA_DprvInd_PubIndstr_ppltn LA code with lAuthPHE_LkupUniq lookup
PHE_centreGrp <- merge(pubCntByLA_DprvInd_PubIndstr_ppltn, lAuthPHE_LkupUniq, by.x="Area code", by.y="LAD19CD")
PHE_centreGrp$LAD19NM <- NULL
#PHE_centreGrp$PHEC19NM <- NULL
PHE_centreGrp[,2:(ncol(PHE_centreGrp) - 2)] <- lapply(PHE_centreGrp[,2:(ncol(PHE_centreGrp) - 2)], as.numeric)
# Public health england region ----------------------------------------------------
# if by PHE Region --------------------------------------------------------------------------------------------
# if by Local Authority -------------------------------------------------------------------
#use casesByLA_DprvInd_PubIndstr_ppltn
# jointWeekNCases_Mltd <- reshape2::melt(casesByLA_DprvInd_Pub_Indstr, id.var = c('lad19_cd', 'lad19_nm', 'IMD_Rank', 'IMD_Decile', 'Income_Rank', 'Income_Decile', 'Employment_Rank', 'Employment_Decile', 'Education_Skills_Training_Rank', 'Education_Skills _Training Decile', 'Health_Deprivation_Disability_Rank', 'Health_Deprivation_Disability_Decile', 'Crime_Rank', 'Crime_Decile', 'Barriers_to_Housing_and_Services_Rank', 'Barriers_to_Housing_and_Services_Decile', 'Living_Environment_Rank', 'Living_Environment_Decile', 'pub_count_2018', 'Retail', 'Transport_Storage_inc_postal', 'Accommodation_food_services', 'Education', 'Health', 'Arts_entertainment_recreation_other_services'), variable.name = 'weekNumber')
# jointWeekNCases_Mltd <- reshape2::melt(PHE_centreGrp, measure.vars = c('wk_05', 'wk_06', 'wk_07', 'wk_08', 'wk_09', 'wk_10', 'wk_11', 'wk_12', 'wk_13', 'wk_14', 'wk_15', 'wk_16', 'wk_17', 'wk_18', 'wk_19', 'wk_20', 'wk_21', 'wk_22', 'wk_23', 'wk_24', 'wk_25', 'wk_26', 'wk_27', 'wk_28', 'wk_29', 'wk_30', 'wk_31', 'wk_32', 'wk_33', 'wk_34', 'wk_35', 'wk_36', 'wk_37', 'wk_38', 'wk_39', 'wk_40', 'wk_41'), variable.name = 'weekNumber')
# names(jointWeekNCases_Mltd)[names(jointWeekNCases_Mltd) == "value"] <- "cvdCaseCount"
# col_idx <- grep("weekNumber", names(jointWeekNCases_Mltd))
# jointWeekNCases_Mltd <- jointWeekNCases_Mltd[, c(col_idx, (1:ncol(jointWeekNCases_Mltd))[-col_idx])]
jointWeekNCases_Mltd <- PHE_centreGrp
col_idx <- grep("PHEC19CD", names(jointWeekNCases_Mltd))
jointWeekNCases_Mltd <- jointWeekNCases_Mltd[, c(col_idx, (1:ncol(jointWeekNCases_Mltd))[-col_idx])]
col_idx <- grep("PHEC19NM", names(jointWeekNCases_Mltd))
jointWeekNCases_Mltd <- jointWeekNCases_Mltd[, c(col_idx, (1:ncol(jointWeekNCases_Mltd))[-col_idx])]
#jointWeekNCases_Mltd[] <- lapply(jointWeekNCases_Mltd, gsub, pattern=',', replacement='')
#jointWeekNCases_Mltd[,6:ncol(jointWeekNCases_Mltd)] <- lapply(jointWeekNCases_Mltd[,6:ncol(jointWeekNCases_Mltd)], as.numeric)
#jointWeekNCases_Mltd <- reshape2::melt(casesByLA_DprvInd_Pub_Indstr, id.var = c('lad19_cd', 'lad19_nm'), variable.name = 'weekNumber')
# get time data ---------------------------------------------------------------------
# unformatWeeks <- colnames(cvdData[, 9:ncol(cvdData)])
# write.csv(x=as.data.frame(unformatWeeks), file="C:\\Installation WorkPCToLaptop\\Dashboard\\cardioDshBCvdDL\\data\\unformatWeeks.csv")
# time month data plus additional cvd model criteria
timeDt <- fread('data/unformatWeeks.csv',  select=c('unformatWeeks', 'LockdownScore', 'TravelSpainEstimate', 'School_Opening', 'QuarantineMeasures'), data.table=FALSE)
## timeDt <- fread('C:\\Installation WorkPCToLaptop\\Dashboard\\cardioDshBCvdDL\\data\\unformatWeeks.csv',  select=c('unformatWeeks', 'Month_Num', 'LockdownScore', 'TravelSpainEstimate', 'School_Opening', 'QuarantineMeasures'), data.table=FALSE)
# Getting latest gov uk cvd dataset case count by local authority ======================================================
# library(ukcovid19)
# query_filters <- c(
# "areaType=ltla"
# )
# query_structure <- list(
# date = "date",
# name = "areaName",
# code = "areaCode",
# daily = "newCasesBySpecimenDate"
# #cumulative = "cumCasesBySpecimenDate"   #cumulative values cannot be summed by week
# )
# localAuthDataLatestCases <- get_data(filters = query_filters, structure = query_structure)
# query_filters <- c(
# "areaType=ltla"
# )
# query_structure2 <- list(
# date = "date",
# name = "areaName",
# code = "areaCode",
# dailyMtly = "newDeathsByDeathDate"
# #cumulativeMtly = "cumDeathsByDeathDate"
# )
# localAuthDataLatestMtly <- get_data(filters = query_filters, structure = query_structure2)
# localAuthDataLatest <- merge(localAuthDataLatestCases, localAuthDataLatestMtly, by=c("code", "name", "date"), all.x = TRUE)
# localAuthDataLatest$cumulative <- NULL
# localAuthDataLatest$cumulativeMtly <- NULL
# localAuthDataLatest[is.na(localAuthDataLatest)] <- 0
# localAuthDataLatest$month <- month(as.POSIXlt(localAuthDataLatest$date))
# #convert from daily to weekly
# library(lubridate) # for the wday() and ymd() functions
# localAuthDataLatest$date <- ymd(localAuthDataLatest$date)
# saturdays <- localAuthDataLatest[wday(localAuthDataLatest$date) == 7, ] # filter for Saturdays
# startDate <- min(saturdays$date) # select first Saturday
# localAuthDataLatest$week <- floor(as.numeric(difftime(localAuthDataLatest$date, startDate, units = "weeks"))) + 5 + 1
# #adjust for weeks by adding 1 (as this dataset starts one week after unformatWeeks); + 5 as unformatWeeks starts at week 5, this one at 1
# #add wk and 0s for single digits
# localAuthDataLatest$week <- sprintf("wk_%02d", localAuthDataLatest$week)
# localAuthDataLatest_Week <-aggregate(. ~ week+code+name, localAuthDataLatest, sum)  #removed month as it causes duplicate weeks
# localAuthDataLatest_Week$date <- NULL
# #Extend last row by constand values for unformatWeeks
# minWk <- as.numeric(max(gsub("wk_", "", unique(timeDt$unformatWeeks)))) + 1
# maxWk <- as.numeric(max(gsub("wk_", "", unique(localAuthDataLatest_Week$week))))
# diff <- maxWk - minWk + 1
# timeDtExtnd <- rbind(timeDt, transform(timeDt[rep(nrow(timeDt), diff),], unformatWeeks = sprintf("wk_%s", minWk:maxWk)))
# #merge unformatWeeks with gov uk mtly and cases data
# localAuthDataLatest_Week_Policy <- merge(localAuthDataLatest_Week, timeDtExtnd, by.x="week", by.y="unformatWeeks")
# write.csv(x=localAuthDataLatest_Week_Policy, file="data/localAuthDataLatest_Week_Policy.csv")
localAuthDataLatest_Week_Policy <- fread('data/localAuthDataLatest_Week_Policy.csv', data.table=FALSE)
localAuthDataLatest_Week_Policy$V1 <- NULL
localAuthDataLatest_Week_Policy$month <- NULL
localAuthDataLatest_Week_Policy$wk_int <- parse_number(localAuthDataLatest_Week_Policy$week) #using wk integer instead of month as part of training
# Getting latest gov uk cvd dataset case count by local authority ======================================================
# merge localAuthDataLatest_Week_Policy week number and lad code with jointWeekNCases_Mltd week number and lad code
jointWeekNCases_Mltd_time <- merge(localAuthDataLatest_Week_Policy, jointWeekNCases_Mltd, by.x="code", by.y="Area code", all.x = TRUE)
col_idx <- grep("PHEC19CD", names(jointWeekNCases_Mltd_time))
jointWeekNCases_Mltd_time <- jointWeekNCases_Mltd_time[, c(col_idx, (1:ncol(jointWeekNCases_Mltd_time))[-col_idx])]
col_idx <- grep("PHEC19NM", names(jointWeekNCases_Mltd_time))
jointWeekNCases_Mltd_time <- jointWeekNCases_Mltd_time[, c(col_idx, (1:ncol(jointWeekNCases_Mltd_time))[-col_idx])]
col_idx <- grep("name", names(jointWeekNCases_Mltd_time))
jointWeekNCases_Mltd_time <- jointWeekNCases_Mltd_time[, c(col_idx, (1:ncol(jointWeekNCases_Mltd_time))[-col_idx])]
colnames(jointWeekNCases_Mltd_time)[which(names(jointWeekNCases_Mltd_time) == "name")]  <- c("lad19_nm")
#jointWeekNCases_Mltd_time$name <- NULL
#using the latest local authority code from gov uk api
colnames(jointWeekNCases_Mltd_time)[which(names(jointWeekNCases_Mltd_time) == "code")]  <- c("lad20_cd")
#Remove NA values
jointWeekNCases_Mltd_time <- jointWeekNCases_Mltd_time[complete.cases(jointWeekNCases_Mltd_time), ]
# get time data ---------------------------------------------------------------------
# combine with local authority spatial data ----------------------------------------------
#use Ultra local authority 2019 ---------------------------------------
engWLAuthBndryLn <- st_read("data/Local_Authority_Districts__December_2019__Boundaries_UK_BUC.shp")
engWLAuthBndryLn$lad19nmw <- NULL
engWLAuthBndryLn$bng_e <- NULL
engWLAuthBndryLn$bng_n <- NULL
engWLAuthBndryLn$st_areasha <- NULL
engWLAuthBndryLn$st_lengths <- NULL
engWLAuthBndryLn$lad19nm <- NULL
engWLAuthBndryLn$objectid <- NULL
engWLAuthBndryLnSF <- sf::st_as_sf(engWLAuthBndryLn)
engWLAuthBndryLnSF_poly <- st_cast(engWLAuthBndryLnSF,"POLYGON")
# remove LA codes not in jointWeekNCases_Mltd_time
engWLAuthBndryLnSF_poly <- engWLAuthBndryLnSF_poly[engWLAuthBndryLnSF_poly$lad19cd %in% as.character(jointWeekNCases_Mltd_time$lad20_cd),]
# remove duplicate LA codes
engWLAuthBndryLnSF_polyUniq <- engWLAuthBndryLnSF_poly[!duplicated(engWLAuthBndryLnSF_poly$lad19cd),]
# merge casesByLA_DprvInd_Pub LA code with industrySizeUniq LA code
jointWeekNCases_Mltd_timeSp <- merge(jointWeekNCases_Mltd_time, engWLAuthBndryLnSF_polyUniq, by.x="lad20_cd",by.y="lad19cd")
# combine with local authority spatial data ----------------------------------------------
# scale data --------------------------------------------------------------------------------------
#dplyr::select_if(jointWeekNCases_Mltd_timeSp, is.numeric)
# jointWeekNCases_Mltd_timeSp[,6:(ncol(jointWeekNCases_Mltd_timeSp) - 1)] <- lapply(jointWeekNCases_Mltd_timeSp[,6:(ncol(jointWeekNCases_Mltd_timeSp) - 1)], as.numeric)
#exclude last column geometry from scaling as it is polygon
#obtain only numeric columns
nums <- unlist(lapply(jointWeekNCases_Mltd_timeSp, is.numeric))
jointWeekNCases_Mltd_timeSp[ , nums]
#preprocess the data by subtracting the mean of each time series and dividing by the standard deviation
#for when some columns have different scale, so make them on same scale (possibly more useful for other features e.g. deprivation indices)
meanTrain <- apply(jointWeekNCases_Mltd_timeSp[ , nums], 2, mean) #only do when other features e.g. deprivation indices have differenr orders of magnitude
stdTrain <- apply(jointWeekNCases_Mltd_timeSp[ , nums], 2, sd)
jointWeekNCases_Mltd_timeSp[, nums] <- scale(jointWeekNCases_Mltd_timeSp[, nums], center = meanTrain, scale = stdTrain)
jointWeekNCases_Mltd_timeSpSortedScaled <- jointWeekNCases_Mltd_timeSp[order(jointWeekNCases_Mltd_timeSp$week),]
colnames(jointWeekNCases_Mltd_timeSpSortedScaled)[which(names(jointWeekNCases_Mltd_timeSpSortedScaled) == "daily")]  <- c("cvdCaseCount")
colnames(jointWeekNCases_Mltd_timeSpSortedScaled)[which(names(jointWeekNCases_Mltd_timeSpSortedScaled) == "dailyMtly")]  <- c("cvdMtlyCount")
# scale data --------------------------------------------------------------------------------------
locAuthList <- unique(jointWeekNCases_Mltd_timeSpSortedScaled$lad19_nm[!is.na(jointWeekNCases_Mltd_timeSpSortedScaled$lad19_nm)])
weekList <- unique(jointWeekNCases_Mltd_timeSpSortedScaled$week[!is.na(jointWeekNCases_Mltd_timeSpSortedScaled$week)])
#weekList <- c(weekList, "wk_42", "wk_43")
# if by Local Authority -------------------------------------------------------------------
# set a random seed for reproducability
set.seed(1)
data_orig <- jointWeekNCases_Mltd_timeSpSortedScaled
data_orig$cvdCaseCount
localAuthDataLatest_Week_Policy
localAuthDataLatest_Week_Policy[localAuthDataLatest_Week_Policy$wk_int == min(localAuthDataLatest_Week_Policy$wk_int) , ]
localAuthDataLatest_Week_Policy[localAuthDataLatest_Week_Policy$wk_int == 6) , ]
localAuthDataLatest_Week_Policy[localAuthDataLatest_Week_Policy$wk_int == 6 , ]
localAuthDataLatest_Week_Policy[localAuthDataLatest_Week_Policy$wk_int == 7 , ]
localAuthDataLatest_Week_Policy[localAuthDataLatest_Week_Policy$wk_int == 8 , ]
localAuthDataLatest_Week_Policy[localAuthDataLatest_Week_Policy$wk_int == min(localAuthDataLatest_Week_Policy$wk_int) , ]
localAuthDataLatest_Week_Policy[localAuthDataLatest_Week_Policy$wk_int == 6 , ]
localAuthDataLatest_Week_Policy[localAuthDataLatest_Week_Policy$wk_int == 7 , ]
localAuthDataLatest_Week_Policy[localAuthDataLatest_Week_Policy$wk_int == 8 , ]
runApp()
localAuthDataLatest_Week_Policy[localAuthDataLatest_Week_Policy$wk_int == 9 , ]
localAuthDataLatest_Week_Policy[localAuthDataLatest_Week_Policy$wk_int == 8 , ]
localAuthDataLatest_Week_Policy[localAuthDataLatest_Week_Policy$wk_int == 8 , ]$daily >0
localAuthDataLatest_Week_Policy[localAuthDataLatest_Week_Policy$wk_int == 9 , ]$daily >0
count(localAuthDataLatest_Week_Policy[localAuthDataLatest_Week_Policy$wk_int == 9 , ]$daily >0)
library("plyr")
count(localAuthDataLatest_Week_Policy[localAuthDataLatest_Week_Policy$wk_int == 9 , ]$daily >0)
localAuthDataLatest_Week_Policy[localAuthDataLatest_Week_Policy$wk_int == 46 , ]$daily == 0
localAuthDataLatest_Week_Policy[localAuthDataLatest_Week_Policy$wk_int == 46 , ]$name
unique(localAuthDataLatest_Week_Policy[localAuthDataLatest_Week_Policy$wk_int == 46 , ]$name)
length(unique(localAuthDataLatest_Week_Policy[localAuthDataLatest_Week_Policy$wk_int == 46 , ]$name))
count(localAuthDataLatest_Week_Policy[localAuthDataLatest_Week_Policy$wk_int == 46 , ]$daily == 0)
localAuthDataLatest_Week_Policy[localAuthDataLatest_Week_Policy$wk_int == 46 , ]$daily == 0
localAuthDataLatest_Week_Policy[localAuthDataLatest_Week_Policy$wk_int == 46 , name]$daily == 0
localAuthDataLatest_Week_Policy[localAuthDataLatest_Week_Policy$wk_int == 46 , "name"]$daily == 0
localAuthDataLatest_Week_Policy[localAuthDataLatest_Week_Policy$wk_int == 46 & localAuthDataLatest_Week_Policy$daily == 0, ]
localAuthDataLatest_Week_Policy[localAuthDataLatest_Week_Policy$wk_int == 1 & localAuthDataLatest_Week_Policy$name == "Shetland Islands"]
localAuthDataLatest_Week_Policy[localAuthDataLatest_Week_Policy$wk_int == 46 & localAuthDataLatest_Week_Policy$name == "Shetland Islands"]
localAuthDataLatest_Week_Policy[localAuthDataLatest_Week_Policy$wk_int == 46 & localAuthDataLatest_Week_Policy$name == "Shetland Islands", ]
localAuthDataLatest_Week_Policy[localAuthDataLatest_Week_Policy$wk_int == 1 & localAuthDataLatest_Week_Policy$name == "Shetland Islands", ]
localAuthDataLatest_Week_Policy[localAuthDataLatest_Week_Policy$wk_int == 10 & localAuthDataLatest_Week_Policy$name == "Shetland Islands", ]
localAuthDataLatest_Week_Policy[localAuthDataLatest_Week_Policy$wk_int == 15 & localAuthDataLatest_Week_Policy$name == "Shetland Islands", ]
localAuthDataLatest_Week_Policy[localAuthDataLatest_Week_Policy$wk_int == 20 & localAuthDataLatest_Week_Policy$name == "Shetland Islands", ]
localAuthDataLatest_Week_Policy[localAuthDataLatest_Week_Policy$wk_int == 50 & localAuthDataLatest_Week_Policy$name == "Shetland Islands", ]
localAuthDataLatest_Week_Policy[localAuthDataLatest_Week_Policy$wk_int == 30 & localAuthDataLatest_Week_Policy$name == "Shetland Islands", ]
localAuthDataLatest_Week_Policy[localAuthDataLatest_Week_Policy$wk_int == 20 & localAuthDataLatest_Week_Policy$name == "Shetland Islands", ]
localAuthDataLatest_Week_Policy[localAuthDataLatest_Week_Policy$wk_int == 10 & localAuthDataLatest_Week_Policy$name == "Shetland Islands", ]
localAuthDataLatest_Week_Policy[localAuthDataLatest_Week_Policy$wk_int == 11 & localAuthDataLatest_Week_Policy$name == "Shetland Islands", ]
localAuthDataLatest_Week_Policy[localAuthDataLatest_Week_Policy$wk_int == 15 & localAuthDataLatest_Week_Policy$name == "Shetland Islands", ]
localAuthDataLatest_Week_Policy[localAuthDataLatest_Week_Policy$wk_int == 17 & localAuthDataLatest_Week_Policy$name == "Shetland Islands", ]
localAuthDataLatest_Week_Policy[localAuthDataLatest_Week_Policy$wk_int == 25 & localAuthDataLatest_Week_Policy$name == "Shetland Islands", ]
localAuthDataLatest_Week_Policy[localAuthDataLatest_Week_Policy$wk_int == 20 & localAuthDataLatest_Week_Policy$name == "Shetland Islands", ]
localAuthDataLatest_Week_Policy[localAuthDataLatest_Week_Policy$wk_int == 46 & localAuthDataLatest_Week_Policy$name == "Shetland Islands", ]
unique(data_orig$lad19_nm)
unique(data_orig$lad19_nm) %in% "Lundy"
unique(data_orig$lad19_nm) == "Lundy"
count(unique(data_orig$lad19_nm) %in% "Lundy")
count(unique(data_orig$lad19_nm) %in% "Isles of Scilly")
runApp()
runApp()
runApp()
jointWeekNCases_Mltd_time$`Estimated Population  mid-2019`
runApp()
install.packages("rjson")
library("rjson")
json_file <- "http://api.worldbank.org/country?per_page=10&region=OED&lendingtype=LNX&format=json"
json_data <- fromJSON(file=json_file)
json_data
json_file
library('MALDIquant', lib.loc='C:/Program Files/R/R-3.2.4revised/library')
library('MALDIquantForeign', lib.loc='C:/Program Files/R/R-3.2.4revised/library')
s <- import("C:/Brucker Dataset/MaldiBiotyperRealTimeClassification", type="auto")
library('MALDIquant', lib.loc='C:/Program Files/R/R-3.2.4revised/library')
library('MALDIquantForeign', lib.loc='C:/Program Files/R/R-3.2.4revised/library')
library('MALDIquantForeign')
s <- import("C:/Brucker Dataset/MaldiBiotyperRealTimeClassification", type="auto")
library('MALDIquant')
library('MALDIquantForeign')
s <- import("C:/Brucker Dataset/MaldiBiotyperRealTimeClassification", type="auto")
s <- import("C:/Brucker Dataset/MaldiBiotyperRealTimeClassification", type="auto")
shiny::runApp()
runApp()
shiny::runApp()
shiny::runApp()
colorSet2 <- c("blue","green","brown4","red","salmon","#7CD3CF","purple","#D29766","orange","cyan", "darkturquoise", "#D64BD6")
library(RColorBrewer)
n <- 45
qual_col_pals = brewer.pal.info[brewer.pal.info$category == 'qual',]
col_vector = unlist(mapply(brewer.pal, qual_col_pals$maxcolors, rownames(qual_col_pals)))
colorSet3 <- sample(col_vector, n)
colorSet2 <- c(colorSet2, colorSet3, "black", "black")
lsoaGrpSF_longLat <- NULL
colorSet2[1]
shiny::runApp()
runApp()
fig$x$data[[i]]$text
fig <- ggplotly(p, autosize = F, width = 650, height = 500)
fig <- plotly_build(fig)
fig$x$layout$annotations[[1]]$text <- ''
p <- ggplot(cvdData, aes(`Local Authority`)) + theme_bw() + geom_line(size = 0.5, na.rm=TRUE, aes(y = LLD_SD_ActualCases_wk46, linetype = "Number of Actual Cases for wk 46: Local lockdown with social distancing", group = 1, color=colorSet2[1])) + geom_line(size = 0.5, na.rm=TRUE, aes(y = LLD_SD_ForecastCases_wk51_Retail50Pct, linetype = "Cases Forecast for wk 51: Local lockdown with social distancing and 50% retail closing", group = 1, color=colorSet2[2])) + geom_line(size = 0.5, na.rm=TRUE, aes(y = LLD_SD_ForecastCases_wk51_FoodAccom50Pct, linetype = "Cases Forecast for wk 51: Local lockdown with social distancing and 50% food & accom closing", group = 1, color=colorSet2[3])) + geom_line(size = 0.5, na.rm=TRUE, aes(y = LLD_SD_ForecastCases_wk51_pub50Pct, linetype = "Cases Forecast for wk 51: Local lockdown with social distancing and 50% pubs closing", group = 1, color=colorSet2[4])) + geom_line(size = 0.5, na.rm=TRUE, aes(y = LLD_SD_ForecastCases_wk51_quarantine100Pct, linetype = "Cases Forecast for wk 51: Local lockdown with social distancing and 100% travel quarantine", group = 1, color=colorSet2[5])) + geom_line(size = 0.5, na.rm=TRUE, aes(y = LLD_SD_ForecastCases_wk51_SchoolOpen50Pct, linetype = "Cases Forecast for wk 51: Local lockdown with social distancing and 50% schools closing", group = 1, color=colorSet2[6])) + geom_line(size = 0.5, na.rm=TRUE, aes(y = LLD_SD_ForecastCases_wk51_IntTravel50Pct, linetype = "Cases Forecast for wk 51: Local lockdown with social distancing and 50% international travel reduction", group = 1, color=colorSet2[7])) + geom_line(size = 0.5, na.rm=TRUE, aes(y = FLD_ForecastCases_wk51, linetype = "Cases Forecast for wk 51: Full lockdown", group = 1, color=colorSet2[8])) + labs(color=NULL) + theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1, margin=margin(5,0,7,0),face="bold")) + xlab("Week") + ylab("Count") + ggtitle("Effect: cases by policy") + theme(legend.margin=margin(10, 0, 50, 0), plot.title = element_text(hjust = 0.5)) + guides(color = guide_legend(override.aes = list(size = 1.5))) + scale_linetype_manual(values = colorSet2)
runApp()
fig$x$data[[i]]$text
fig$x$data[[1]]$text
colorSet2[1]
fig$x$data
cvdData
cvdData$LLD_SD_ForecastCases_wk51_IntTravel50Pct
cvdData$LLD_SD_ActualCases_wk46
sub("as.factor.*", "", fig$x$data[[i]]$text)
runApp()
library(stringr)
library(dplyr
)
runApp()
shiny::runApp()
runApp('app BK 20201127 started adding model tab.R')
runApp('app BK 20201130 started adding cases model variable importance.R')
tiff(filename=‘figure.tiff’, res=300, unit=‘in’)
plot()
Dev.off()
tiff(filename='figure.tiff', res=300, unit=‘in’)
plot()
Dev.off()
tiff(filename='figure.tiff', res=300, unit='in')
plot()
Dev.off()
tiff()
tiff(filename='figure.tif', res=300, unit='in')
plot()
Dev.off()
tiff(file = "temp.tiff", width = 3200, height = 3200, units = "px", res = 800)
plot(1:10, 1:10)
dev.off()
runApp('app BK 20201130 started adding cases model variable importance.R')
runApp()
knitr::opts_chunk$set(echo = TRUE)
library(readxl)
library(data.table)
library(ggplot2)
library(plotly)
library(knitr)
DT1 <- setDT(read_xlsx("St69_St131_train.xlsx", col_names = F))
library(readxl)
library(data.table)
library(ggplot2)
library(plotly)
library(knitr)]
library(knitr)
DT1 <- setDT(read_xlsx("C:\Users\qd18830\OneDrive - University of Bristol\Documents\PhD\WFMM\Clustering ST strain types\St69_St131_train.xlsx", col_names = F))
getwd()
library(readxl)
library(data.table)
library(ggplot2)
library(plotly)
library(readxl)
library(data.table)
library(ggplot2)
library(plotly)
library(knitr)
DT1 <- setDT(read_xlsx("St69_St131_train.xlsx", col_names = F))
getwd()
